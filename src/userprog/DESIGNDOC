                     +--------------------------+
       	       	     |          CS 124          |
                     | PROJECT 4: USER PROGRAMS |
                     |     DESIGN DOCUMENT      |
                     +--------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Tim Holland <tholland@caltech.edu>
Daniel Kong <dkong@caltech.edu>
Daniel Wang <dwang@caltech.edu>

>> Specify how many late tokens you are using on this assignment: 0

>> What is the Git repository and commit hash for your submission?

   Repository URL: https://github.com/dkong1796/pintos-hkw.git
   commit master:dcad0de
   tag: project4

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course instructors.

                           ARGUMENT PASSING
                           ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

We didn't declare or change anything that belongs here.

---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?

We used strtok_r to split the string into space-separated tokens, then
use the pointer to esp to push each token onto the stack. When we do
this, we put the pointer to each arg in an array, and place a NULL at the end
of the array. Then, we word-align the stack and iterate through the array
of memory addresses backwards, ensuring that our arguments are push in
the correct order. We then push argv, argc and a dummy return value.

To avoid overflowing the stack page, we check to ensure that the length
of the arguments plus the length of the argument pointers plus the
additional things pushed onto the stack (argv, argc, NULL, dummy return, word-
align) does not exceed page size. If it does, we terminate the process.

---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?

strtok_r is reentrant, so it is a thread safe function. strtok is not, and
has undefined behavior if called from multiple threads. Since we have a
lot of concurrency going on, we want the thread safe version, since it
will be safer and more correct than strtok.

>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.

If the shell does this, we can cut out unnecessary code from the kernel,
making it easier to maintain and closer to the microkernel ideal. This
improves the scalability of the kernel without trading too much in
performance.

In addition, if we keep the argument parsing in user space, we don't need
to worry so much about checking invalid memory, since this is already done
by the kernel. Since we're in user space, we handle this through segfaults
and existing syscall code. This cuts down on the amount of error-checking
code that needs to be written, improving code readability.

                             SYSTEM CALLS
                             ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In lib/kernel, we have an implementation of a dynamic array in vector.h
and vector.c (similar to a C++ vector). The data structure and usage
is documented in those two files.

In threads/thread.h:

- We declared type pid_t as an int, as we use a 1-to-1 mapping of tids to pids.

- We added a struct vector files to struct thread. This vector keeps
  array of file * pointers for all files opened by the thread.

- We declared struct exit_state as:

struct exit_state {
    tid_t parent;
    int exit_status;
    bool load_successful;
    struct semaphore launching;
    struct semaphore waiting;
};

  We use this struct to keep track of thread's exit status and use it for
  waiting and checking the status of the exec() system call.

- We declared a global struct vector thread_exit_status that contains an
  array of struct exit_state * pointers. Each thread has its own struct
  exit_state, indexed by its tid.

- We declared a global struct lock filesys_lock used to make sure that
  all filesystem operations were atomic.

In threads/thread.c:

- We declared thread_exit_status and filesys_lock as mentioned above (since
  they were declared extern in thread.h).

>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?

Each file maintains its own vector of files. A file descriptor is unique
only within each thread and are not shared between threads. To access
the file at file descriptor fd of thread t, we simply do one of the
following (both are equivalent):

file *f = t->files.data[fd];
file *f = vector_get(&t->files, fd);

When we open a file, we store its file * pointer at the next available
index of the vector and return that as the file descriptor. If none are
available, we append it to the vector (which take amortized O(1) time
because it's a dynamic array).

When we close a file, we set the file * pointer at index fd to NULL, which
makes that file descriptor available again.

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.

After ensuring stack and argument adresses are valid, we examine the buffer
pointer as well as the buffer + size - 1. We also ensure that the file
descriptor given to us is valid (non-null and not STDIN/STDOUT for write
and read, respectively). If any of these checks fail, we exit with status
-1.

For reading, we have a special case if fd == STDIN_FILENO that calls
input_getc to read from the keyboard. Otherwise, we acquire the filesys
lock and call the file_read function on the file in index fd of the files
vector of the current thread. We release the lock and return the value
passed to us by the filesys function.

For writing, we have a special case if fd == STDOUT_FILENO that calls
putbuf to write to the console. Otherwise, similar to read, we acquire
the filesys lock, call the file_write function, release the lock, and
return the value passed to us.

>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?

The maximum number of page table inspections is 2 for both 4096 and
2 bytes. For 4096, it is unlikely that there exists much room for
improvement without wasting a lot of memory, since there exists only one
possible arrangement of memory that will allow the data to fit on a
single page. On the other hand, for 2 bytes, we can easily ensure that
only one page is examined by checking if the data crosses a page boundary
and moving it over to the beginning of the second page. This wastes a
byte of memory, but the time savings outweigh this small cost. On the
other hand, for the 4096 byte block, if we were to do the same thing, we
would waste a much larger amount of memory, causing fragmentation issues.

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.

The wait system call uses process_wait() on the provided tid, since we
have an identity mapping between tids and pids. Our process_wait()
implementation uses the thread_exit_status vector to look up the
exit status of its child.

This is what happens in process_wait():

- We look up the struct exit_status * that contains exit information for
  a given thread using the thread_exit_status vector. If this doesn't exist
  (the pointer is NULL), then the parent has already waited for this child
  and immediately returns -1. Also if the tid is invalid or the thread is
  not a child of the parent, then we return -1.

- We call sema_down on the semaphore in the struct exit_status. This will
  block the parent until the child finishes executing - the child calls
  sema_up when it exits. If the child has already exited, then the
  semaphore has a value of 1, so sema_down works immediately.

- We then look up the exit status stored in the struct and return it. We
  also free the memory and set the pointer to NULL so that the parent
  cannot wait on this child again.

When a child exits, it calls sema_up() on its semaphore just before it
calls schedule, inside the interrupt disabled section. This ensures that
the parent can't preempt the child before all resources are freed.

>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.

Our syscall handler immediately checks the passed stack pointer in order to
ensure the syscall number can be obtained. We then enter into a huge switch
block, with a case for each syscall number. In each of these calls with
additional arguments, we call a function, check_args_x(), where x is 1, 2,
or 3. This checks the validity of the arguments on the stack, and cuts
down on redundancy. If any of these checks fail, we exit with return value
-1. With this design, we centralize all of our stack/argument pointer
error checking. We still must check validity of pointers passed as arguments
to the syscalls, which is done in each individual call, but because these are
specific to the call, this decentralization is unavoidable.

When an error is detected, we free all resources by calling exit(-1). This
terminates the process and thread. In thread termination, we iterate through
the list of locks held by the thread and release all of them. In process
termination, we destroy the page directory, close open files, and delete the
vector of file descriptors.

Suppose we have a call to close. Our program will check the passed stack
pointer for validity, then dereference it for the syscall number. Then, it
will proceed to the SYS_CLOSE case and examine the single argument. It then
calls sys_close(). This function validates the file descriptor passed to it.
If this check fails, then we call exit(-1), which causes thread
termination (releasing locks) and process termination (freeing memory and
closing files).

---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?

In our vector of thread_exit_status', we have two relevant fields
in the struct exit_state: bool load_successful and
struct semaphore launching. The system handler sys_exec at syscall.c:197
first calls process_execute on the cmd_line that is passed to it.
However, process_execute is not able to see directly if the
load works properly, because the call to load is passed off to
the child thread before the payload begins to run. What process_execute
does is initialize the semaphore named "launching" to 0. When
load completes, the exit_state's load_successful field is set
to true if the program is loaded correctly and false otherwise.
the child process then raises the semaphore "launching", and
either continues with the payload or quits if appropriate. Meanwhile,
the syscall handler is waiting is sys_exec because it is waiting
to lower the "launching" semaphore. Once it can lower it, it knows
that the load_succesful field is appropriately set and can either
return the pid returned from process_execute or -1.

>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

When P waits on C, P calls sema_down() on the semaphore in the exit_status
struct associated with C. This makes P block until C calls sema_up, which
happens at the very end of thread_exit(). This way, P cannot return until
C has exited. If P calls wait after C exits, then the semaphore has a value
of 1, so sema_down() doesn't block. The child's resources are always freed
because it won't call sema_up until all resources (locks and files) have
been freed.

Clearing up C's resources has nothing to do with P, since the exit status
is stored in a global vector. It cleans itself up in thread_exit().

---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?

We chose the simpler method of user memory access for ease of debugging
and maintenance. We centralized our memory checks as much as possible to
cut down on redundancy and improve code readability. When handling syscalls,
we centrally check that all the locations on the stack where the arguments
are passed are valid, and then let each syscall function check that each
of the arg's values are valid. That is, we do two checks - one before
dereferencing the stack to get the arg, and one before we dereference the
arg.

>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?

By using a dynamic array, we save space inside of the thread struct,
allowing for more space for the stack. In addition, we have the
benefit of constant time random access, along with a theoretical
infinite bound to the number of open files. As a tradeoff, the complexity
of code is increased, since we wrote an entire dynamic array. It also
makes the closing of files slightly more painful, since we need to keep
track of which entries are NULL and replace them with new files if
necessary in order to save space.

>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?

We maintained the original identity mapping.

                           SURVEY QUESTIONS
                           ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the feedback survey on the course
website.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
Whoo!
