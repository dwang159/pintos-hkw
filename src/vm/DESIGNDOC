       	       	    +---------------------------+
                    |           CS 124          |
                    | PROJECT 5: VIRTUAL MEMORY |
                    |      DESIGN DOCUMENT      |
                    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Timothy Holland <tholland@caltech.edu>
Daniel Kong <dkong@caltech.edu>
Daniel Wang <dwang@caltech.edu>

>> Specify how many late tokens you are using on this assignment: 2

>> What is the Git repository and commit hash for your submission?

   Repository URL: http://github.com/dkong1796/pintos-hkw.git
   commit ...

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.
So Donnie gave us an extension to Monday the 10th... And then
we used two late tokens to get us to Wednesday... and then we
submitted on Thursday. So that's like a day late right?
Only a 10% penalty? (have mercy?)

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course instructors.

en.wikipedia.org/wiki/Virtual_memory

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Describes the kind of access for that entry
    enum spt_page_type {
        SPT_INVALID,
        SPT_ZERO,
        SPT_FILESYS,
        SPT_SWAP
    };

A correspondence between user page addresses and SPT entries
    struct spt_table {
        struct hash data;
    };

/* Data structure for a supplemental page table entry. */
struct spt_entry {
    // Element used to store entry in page table.
    struct hash_elem elem;

    // Key used to identify page. Should be the uaddr of the page with
    // the lower 12 bits zeroed out.
    unsigned key;

    // Page status (where to read and write data).
    enum spt_page_type read_status;
    enum spt_page_type write_status;

    // Switch the union based on read and write type.
    union {
        // Additional data about the page, depending on the page type.
        // Struct to keep information on the location of the
        // page within the file.
        struct {
            struct file *file;
            off_t offset;
            int read_bytes;
            int zero_bytes;
        } fdata;

        // Used if associated with swap.
        size_t slot;
    } data;

    bool writable;
    bool is_mmap;
};

---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

The faulting address can be used to index into the supplementary page table.
From there, there is a data structure that provides the decision making
about what actions to take and the data for that action.

If the page has a read_status of SPT_ZERO, the page it is gifted
is memset to 0. If it has a read_status of SPT_FILESYS, it looks into
the fdata structure for a struct file pointer, an offset, and the number
of bytes to read and the number of bytes to zero as in load_segment. If
the read_status is SPT_SWAP, it asks the swap table to fill it's frame
with the contents numbered `slot.`

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

We avoid this issue by using dirty bits looked up in
thread_current()->pagedir.

---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?

We used a lock around the frame allocator. If A and B fault at around
the same time, one of them will have to wait until the other is given
a frame and goes along its way until it is given one.

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?

It enabled us efficient lookup of a wide number of mappings, and
switiching on the read_status and write_status on either faults
or eviction allowed us to have a pretty uniform treatment of entries
whether coming from 0, a loaded file, or a mapped file.

		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Lock for the swap table, preventing simultaneous access
static struct lock swap_table_lock;

Bitmap representing filled swap slots in the swap table
static struct bitmap *swap_table;

The swap partition
static struct block *swap_dev;

/* Contains all elements of the frame table. */
struct frame_table {
    struct hash data;
};

/* An element of the frame table. */
struct frame_entry {
    // Element used to store entry in frame table.
    struct hash_elem elem;

    // Key used to identify page. This is a pointer to a kernel page,
    // and the key is retrieved using frame_get_key().
    unsigned key;

    // Thread and key for the supplemental page table associated with
    // this frame.
    struct thread *owner;
    unsigned ukey;
};

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

Our algorithm represents a modified second-chance policy. Rather than choose
the first frame we see if all pages have been accessed, we choose the last
one that we see. Otherwise, our algorithm should behave the same. We iterate
through the members of the frame table, setting the accessed bit to false if
it is set and evicting otherwise.

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

After choosing a frame to evict, we write the frame's contents to disk.
Each frame keeps track of the thread owning it and its ukey (the user
address key for the supplemental page table), so it looks up its supplemental
page table entry. We then write the frame back to disk - if the write
status is set to SPT_SWAP, we find a slot in the swap table and write
the data to swap, and otherwise if it is set to SPT_FILESYS, we look
up the relevant file data in the supplemental page table and write the data
back to that location. We then update the page's read status to read from
wherever we wrote the data.

After writing back the data, we evict the frame (by clearing its pagedir
entry), free the frame entry struct containing it, create a new frame
for P, and insert P's data into the frame.

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

We define a maximum size for the stack (8MB), and define a STACK_HEURISTIC
value (set at 32 currently). Then, in the page fault handler, if no spt
entry exists for the address, we check if the address is >= to
esp - STACK_HEURISTIC and PHYS_BASE - MAX_STACK and that the address is
less than PHYS_BASE. If this is true, we determine that it is a stack
access and grow the stack.

---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

We lock the 2 global structures (frame and swap) any time we access them,
making it so only one process can interact with it at any time. We acquire
the lock whenever we access that particular data structure in other kernel
code. To prevent deadlock, we ensure that any calls between the code of our
data structures doesn't attempt to acquire a lock multiple times. We further
avoid calling functions in our data structures that acquire other data
structures' locks. For example, we call swap functions from frame, but
we avoid obtaining the frame lock in swap, making it so deadlock cannot occur.

>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

Because the frame table is locked until P finishes evicting, Q will not
fault the frame back in until P has finished evicting it.

>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

Again, the frame table is locked while reading a page in, so Q cannot evict
that frame until P finishes reading it in.

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

We use the page fault to bring in pages, treating it exactly like virtual
addresses. When we attempt to access an invalid virtual address, if it is
in the supplemental page table, we fault it in. If it is a stack page, we
allocate a new zeroed page. If it is entirely invalid, we kill the user
process that tried to access the address.

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

We only lock the global structures (which makes sense, as these are the
only ones that can be accessed by multiple threads). This is still
relatively coarse, since we lock the entire frame and swap table, but
it guarantees absence of race conditions, which is highly desirable
when debugging. Finer locking would result in more parallelism, but we
already struggled greatly to debug this project, so it is also
probably impossible in the given time frame.

			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

A per-process hashmap between mapid_ts and fmap'd files.

/* File mapping data structure */
struct fmap_table {
    struct hash data;
};

struct fmap_entry {
    void *addr;  // The address the file is mapped into
    int fd;      // The file descriptor given by the process
    struct file *hidden; // The file is reopened by the kernel so
                         // that if the child closes it, it is still open.
    unsigned num_pages; // the number of pages for the file
    unsigned key; // the mapid for the file
    struct hash_elem elem; // Used to index into the hash table
};

// Incremented and given out each time a mapping is asked for by
// a process.
static mapid_t key_giver = 0;

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.
On mapping, the file's SPT entries are filled out but the file
is not loaded. Then on a fault, the page_fault handler will
consult the spt and realize to look into the file and find
the contents there.
    There is a member "is_mmap" for the spt_entry struct that indicates
whether memory belonging to a loaded file or a mapped file. If it
belongs to a loaded file, it is paged out on eviction to swap but if
it belongs to a mapped file it is written back to the file. While
the file is mapped, these SPT entries remain but are removed upon
munmap.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.
We used a hash_iterator over the supplementary page table, and
compared the start and end addresses of the new segment with
all of the old pages. For any pair of extents a1-a2 and b1-b2,
there is no overlap if
    whenever a1 < b2, b1 >= a2 and vice versa.
    That is, whenever a starts before b ends, b starts after a ends.
We just check that this is the case for all pages currently mapped. This
could be more efficient if we just kept track of mapped segments.
---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.
It does share a lot. Probably the only major difference is in
upon a pagefault, it reads it into memory differently on
the contents of spte->is_mmap: they both have SPT_FILESYS for
their read status but loaded files have SPT_SWAP as it's write_status and
the mmapped files have SPT_FILESYS.

         SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the feedback survey on the course
website.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?
This took a huge amount of time, and it was very hard. Debugging was
possible, but very difficult and required a very methodical and slow
approach. Alternately, the radical approach of starting over from scratch
also worked. There was very little middle ground. Also compared to
assignments 3 and 4 (threads and user programs), this assignment took
much longer (we spent at least twice as much time on this assignment compared
to either 3 or 4).

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?
Yes. I have a much better understanding of how to manage resources for
multiple "guests" simultaneously.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
Ugh.
